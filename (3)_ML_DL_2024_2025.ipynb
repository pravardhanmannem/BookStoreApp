{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "9kYN3knWMFEL"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/FatiZaha/BookStoreApp/blob/main/(3)_ML_DL_2024_2025.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Introduction au Machine Learning\n",
        "\n",
        "Bienvenue à la session pratique de notre premier cours d'apprentissage automatique ! Dans ce notebook, nous allons plonger dans les concepts de régression et de classification, en incorporant diverses techniques et observations pour comprendre leur impact sur la performance des modèles.\n",
        "\n",
        "Ce notebook est conçu non seulement pour vous guider à travers des implémentations pratiques, mais aussi pour servir de ressource d'apprentissage complète. Vous trouverez des explications détaillées et des exemples pour vous aider à saisir les concepts sous-jacents."
      ],
      "metadata": {
        "id": "cTt3wuAK-jQK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Configuration <a name=\"setup\"></a>"
      ],
      "metadata": {
        "id": "XIHxeMe73-JL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tout d'abord, nous allons importer les bibliothèques nécessaires. Ces bibliothèques nous fourniront les outils pour le traitement des données, la visualisation et la modélisation."
      ],
      "metadata": {
        "id": "1odf673Q7obf"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6R2pHxUW-HyU"
      },
      "outputs": [],
      "source": [
        "# Importer les bibliothèques essentielles\n",
        "import numpy as np               # Pour les calculs numériques\n",
        "import pandas as pd              # Pour la manipulation des données\n",
        "import matplotlib.pyplot as plt  # Pour la visualisation des données\n",
        "import seaborn as sns            # Pour des visualisations statistiques avancées\n",
        "\n",
        "# Ignorer les avertissements pour un affichage plus clair\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Bibliothèques d'apprentissage automatique\n",
        "from sklearn.linear_model import LinearRegression, LogisticRegression   # Modèles de régression et classification\n",
        "from sklearn.preprocessing import PolynomialFeatures, StandardScaler    # Pour la création de caractéristiques polynomiales et la mise à l'échelle\n",
        "from sklearn.tree import DecisionTreeRegressor, DecisionTreeClassifier  # Modèles d'arbres de décision pour régression et classification\n",
        "from sklearn.model_selection import train_test_split, cross_val_score   # Pour la division des données et la validation croisée\n",
        "from sklearn.metrics import (\n",
        "    mean_squared_error, mean_absolute_error,                            # Métriques pour la régression\n",
        "    accuracy_score, precision_score, recall_score, f1_score,            # Métriques pour la classification\n",
        "    confusion_matrix, ConfusionMatrixDisplay                            # Pour la matrice de confusion\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Chargement et Exploration des Données <a name=\"data-loading-and-exploration\"></a>"
      ],
      "metadata": {
        "id": "Hfj21tze_Tj6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.1 Chargement du Jeu de Données pour la Régression"
      ],
      "metadata": {
        "id": "WuQeeHuo-PIw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Nous allons utiliser la dataset California Housing de scikit-learn. C'est un ensemble de données de régression contenant des informations sur les logements en Californie, basé sur le recensement de 1990. Il inclut des caractéristiques telles que le revenu médian des ménages, l'âge médian des maisons, le nombre moyen de pièces et de chambres par maison, la population, le nombre moyen d'occupants, ainsi que la latitude et la longitude des quartiers. La variable cible est la valeur médiane des maisons (en centaines de milliers de dollars). Cet ensemble de données est souvent utilisé pour des tâches d'apprentissage supervisé, notamment pour explorer et modéliser des relations entre des caractéristiques socio-économiques et les prix des logements."
      ],
      "metadata": {
        "id": "C64Rz4C488Js"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Charger l'ensemble de données\n",
        "from sklearn.datasets import fetch_california_housing\n",
        "housing = fetch_california_housing()\n",
        "\n",
        "# Convertir en DataFrame pandas\n",
        "data = pd.DataFrame(housing.data, columns=housing.feature_names)\n",
        "data['MedHouseVal'] = housing.target\n",
        "\n",
        "# Afficher les cinq premières lignes\n",
        "data.head()"
      ],
      "metadata": {
        "id": "lohAxj5T_QT-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Caractéristiques** :\n",
        "\n",
        "- MedInc : Revenu médian dans le groupe de blocs.\n",
        "- HouseAge : Âge médian des maisons dans le groupe de blocs.\n",
        "- AveRooms : Nombre moyen de pièces par ménage.\n",
        "- AveBedrms : Nombre moyen de chambres par ménage.\n",
        "- Population : Population du groupe de blocs.\n",
        "- AveOccup : Nombre moyen de membres du ménage.\n",
        "- Latitude : Latitude du groupe de blocs.\n",
        "- Longitude : Longitude du groupe de blocs.\n",
        "\n",
        "**Cible** :\n",
        "\n",
        "- MedHouseVal : Valeur médiane des maisons pour les districts de Californie (en $100,000).\n",
        "\n",
        "Ces informations nous aideront à prédire la valeur médiane des maisons en fonction des caractéristiques fournies."
      ],
      "metadata": {
        "id": "HssvY0UI_f5Z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.2 Chargement du Jeu de Données pour la Classification"
      ],
      "metadata": {
        "id": "cGvzhBPw-Sqy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Le jeu de données Iris est un ensemble de données d’apprentissage supervisé contenant 150 échantillons de trois espèces de fleurs d'iris : Setosa, Versicolor et Virginica. Chaque échantillon est décrit par quatre caractéristiques numériques : la longueur et la largeur des sépales, ainsi que la longueur et la largeur des pétales (toutes mesurées en centimètres). La variable cible indique l'espèce à laquelle chaque échantillon appartient. Cet ensemble de données est largement utilisé comme point de départ pour expérimenter des algorithmes de classification supervisée, grâce à sa simplicité et à sa petite taille."
      ],
      "metadata": {
        "id": "Avbomcxo-WUP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Charger le jeu de données Iris\n",
        "from sklearn.datasets import load_iris\n",
        "iris = load_iris()\n",
        "\n",
        "# Convertir en DataFrame pandas\n",
        "iris_data = pd.DataFrame(iris.data, columns=iris.feature_names)\n",
        "iris_data['Species'] = iris.target\n",
        "\n",
        "# Afficher les cinq premières lignes\n",
        "iris_data.head()"
      ],
      "metadata": {
        "id": "4yhBfwWd-ydw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Explication** :\n",
        "\n",
        "load_iris() charge le jeu de données Iris.\n",
        "Nous créons un DataFrame pandas pour faciliter l'exploration et le prétraitement.\n",
        "iris_data.head() nous donne un aperçu des données.\n",
        "Comprendre le Jeu de Données Iris\n",
        "\n",
        "**Caractéristiques** :\n",
        "\n",
        "sepal length (cm) : Longueur du sépale en centimètres.\n",
        "sepal width (cm) : Largeur du sépale en centimètres.\n",
        "petal length (cm) : Longueur du pétale en centimètres.\n",
        "petal width (cm) : Largeur du pétale en centimètres.\n",
        "\n",
        "**Cible** :\n",
        "\n",
        "Species : Classe de l'iris (0: setosa, 1: versicolor, 2: virginica).\n",
        "\n",
        "Le jeu de données Iris est un classique en apprentissage automatique pour les tâches de classification."
      ],
      "metadata": {
        "id": "MmZ-faQ7-337"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Prétraitement des Données <a name=\"data-preprocessing\"></a>\n"
      ],
      "metadata": {
        "id": "u6gaqV3R_yf-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Le prétraitement des données est une étape cruciale qui peut affecter significativement la performance du modèle. Il inclut la gestion des valeurs manquantes, l'ingénierie des caractéristiques, la sélection des caractéristiques et la mise à l'échelle."
      ],
      "metadata": {
        "id": "EroZsNpT-Cev"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.1 Gestion des Valeurs Manquantes <a name=\"handling-missing-values\"></a>"
      ],
      "metadata": {
        "id": "q-xjauu3-F5x"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pour le jeu de données California Housing :\n"
      ],
      "metadata": {
        "id": "yAEvq2Kk_Q4v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check for missing values\n",
        "missing_values = data.isnull().sum()\n",
        "print(missing_values)"
      ],
      "metadata": {
        "id": "1TD3AZSK_bKP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Observation** : Pas de valeurs manquantes."
      ],
      "metadata": {
        "id": "CDBtNX2R_YUn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pour le jeu de données Iris :\n"
      ],
      "metadata": {
        "id": "8uquGCSV_ZFE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Vérifier les valeurs manquantes\n",
        "missing_values_iris = iris_data.isnull().sum()\n",
        "print(\"\\nValeurs manquantes dans le jeu de données Iris :\")\n",
        "print(missing_values_iris)"
      ],
      "metadata": {
        "id": "BdQq-MOk_cfs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Observation** : Pas de valeurs manquantes."
      ],
      "metadata": {
        "id": "hu4n5WfN_krW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.2 Ingénierie des Caractéristiques <a name=\"feature-engineering\"></a>\n"
      ],
      "metadata": {
        "id": "ubGKjv5b_rlK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "L'ingénierie des caractéristiques consiste à créer de nouvelles caractéristiques à partir des données existantes pour améliorer la performance du modèle.\n",
        "\n"
      ],
      "metadata": {
        "id": "YwQ_Qb7wAAoz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pour le jeu de données California Housing :"
      ],
      "metadata": {
        "id": "nNQBxtTk_ye-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create new features\n",
        "data['RoomsPerHousehold'] = data['AveRooms'] / data['AveOccup']\n",
        "data['BedroomsPerRoom'] = data['AveBedrms'] / data['AveRooms']\n",
        "data['PopulationPerHousehold'] = data['Population'] / data['AveOccup']"
      ],
      "metadata": {
        "id": "FxYBjTaf_-d8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Explication** :\n",
        "\n",
        "- RoomsPerHousehold : Le nombre moyen de pièces par ménage, ce qui peut indiquer la taille des logements.\n",
        "- BedroomsPerRoom : La proportion de chambres par rapport aux pièces, reflétant la taille des chambres ou la disposition des maisons.\n",
        "- PopulationPerHousehold : Le nombre moyen de personnes par ménage, indiquant la densité d'occupation.\n",
        "\n",
        "Ces nouvelles caractéristiques peuvent capturer des informations non évidentes dans les données originales."
      ],
      "metadata": {
        "id": "c7ge6dFB_5Bh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.3 Sélection des Caractéristiques <a name=\"feature-selection\"></a>\n"
      ],
      "metadata": {
        "id": "B-kLONNqAAaw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "La sélection des caractéristiques vise à choisir les variables les plus pertinentes pour le modèle.\n"
      ],
      "metadata": {
        "id": "X85PicnIAKJP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculer la matrice de corrélation\n",
        "corr_matrix = data.corr()\n",
        "\n",
        "# Trier les corrélations avec la variable cible\n",
        "corr_with_target = corr_matrix['MedHouseVal'].sort_values(ascending=False)\n",
        "print(\"Corrélations avec la variable cible :\")\n",
        "print(corr_with_target)"
      ],
      "metadata": {
        "id": "ZNgfxpFxAGmu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Observation** :\n",
        "\n",
        "*Analyse des corrélations\n",
        "\n",
        "- Revenu médian (MedInc) : La plus forte corrélation positive avec la variable cible (0.688), ce qui indique que le revenu médian est un facteur important influençant la valeur des maisons. Plus le revenu médian est élevé, plus la valeur des maisons tend à être élevée.\n",
        "\n",
        "- Nombre moyen de pièces (AveRooms) : Corrélation positive mais faible (0.151). Cela suggère que le nombre de pièces par maison a un impact limité sur la valeur des maisons.\n",
        "\n",
        "- Âge médian des maisons (HouseAge) : Corrélation positive très faible (0.105). L'âge des maisons joue un rôle mineur dans la détermination des prix.\n",
        "\n",
        "- Nombre moyen d'occupants (AveOccup), population (Population), latitude (Latitude), longitude (Longitude), et nombre moyen de chambres (AveBedrms) : Ces variables ont des corrélations faibles ou négatives avec la valeur des maisons. Par exemple, la latitude (-0.144) indique que les maisons situées plus au nord tendent à avoir des valeurs plus faibles.\n",
        "\n",
        "*Interprétation\n",
        "\n",
        "- La caractéristique la plus pertinente pour prédire la valeur des maisons est le revenu médian des ménages (MedInc).\n",
        "- Les autres caractéristiques montrent des corrélations faibles ou négligeables, mais elles pourraient encore être utiles en combinaison avec d'autres variables dans un modèle d'apprentissage.\n",
        "\n",
        "Sélection des Caractéristiques Basée sur la Corrélation :"
      ],
      "metadata": {
        "id": "V6GWGdaMATBh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "selected_features = [\n",
        "    'MedInc', 'Latitude', 'Longitude', 'RoomsPerHousehold',\n",
        "    'BedroomsPerRoom', 'PopulationPerHousehold', 'HouseAge'\n",
        "]\n",
        "X = data[selected_features]\n",
        "y = data['MedHouseVal']"
      ],
      "metadata": {
        "id": "8jeK8TmSAQKf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "En sélectionnant les caractéristiques les plus pertinentes, nous simplifions le modèle et réduisons le risque de surajustement.\n",
        "Cela peut également améliorer la performance et la vitesse d'entraînement du modèle."
      ],
      "metadata": {
        "id": "O74tTMSTBrEr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.4 Mise à l'Échelle des Caractéristiques <a name=\"feature-scaling\"></a>\n"
      ],
      "metadata": {
        "id": "w5As3iexAgKP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "La mise à l'échelle des caractéristiques peut impacter les algorithmes qui reposent sur des calculs de distance."
      ],
      "metadata": {
        "id": "yIqxarlPBwbH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the scaler\n",
        "scaler = StandardScaler()\n",
        "\n",
        "# Fit and transform the features\n",
        "X_scaled = scaler.fit_transform(X)"
      ],
      "metadata": {
        "id": "Nj1IQdaXAdz2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Explication** :\n",
        "\n",
        "StandardScaler standardise les données en supprimant la moyenne et en les mettant à l'échelle de la variance unitaire.\n",
        "Cela assure que chaque caractéristique contribue de manière égale au modèle.\n",
        "\n",
        "De même pour le jeu de données Iris :"
      ],
      "metadata": {
        "id": "i7Mujh9xB76C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Séparer les caractéristiques et la cible\n",
        "X_iris = iris_data.drop('Species', axis=1)\n",
        "y_iris = iris_data['Species']\n",
        "\n",
        "# Mettre à l'échelle les caractéristiques\n",
        "X_iris_scaled = scaler.fit_transform(X_iris)"
      ],
      "metadata": {
        "id": "-UoF86FeCFaO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Division Entraînement-Test <a name=\"train-test-split\"></a>\n"
      ],
      "metadata": {
        "id": "sBYEwU4pCNKm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Diviser les données en ensembles d'entraînement et de test est essentiel pour évaluer la capacité du modèle à généraliser."
      ],
      "metadata": {
        "id": "AZJACcXXAquQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Split data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X_scaled, y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "ES_83pRJAlDG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Explication** :\n",
        "\n",
        "- test_size=0.2 signifie que 20% des données sont réservées pour le test.\n",
        "- random_state=42 assure la reproductibilité des résultats.\n",
        "\n",
        "Pour le jeu de données Iris :"
      ],
      "metadata": {
        "id": "kCmfDKemCb3d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Diviser les données\n",
        "X_train_iris, X_test_iris, y_train_iris, y_test_iris = train_test_split(\n",
        "    X_iris_scaled, y_iris, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "OO8pyy9mCwUH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. Entraînement et Comparaison des Modèles <a name=\"model-training-and-comparison\"></a>\n",
        "### 5.1 Effet de la Mise à l'Échelle des Caractéristiques <a name=\"effect-of-feature-scaling\"></a>\n",
        "Nous allons comparer des modèles de Régression Linéaire entraînés avec et sans mise à l'échelle des caractéristiques.\n",
        "\n",
        "5.1.1 Régression Linéaire sans Mise à l'Échelle"
      ],
      "metadata": {
        "id": "0Sb51ppYA0b4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Train without scaling\n",
        "lr_no_scaling = LinearRegression()\n",
        "lr_no_scaling.fit(X_train, y_train)\n",
        "\n",
        "# Predict on test set\n",
        "y_pred_no_scaling = lr_no_scaling.predict(X_test)"
      ],
      "metadata": {
        "id": "Jujz9KYDA5zw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Explication** :\n",
        "\n",
        "- Nous utilisons les données sans mise à l'échelle pour voir si cela affecte la performance du modèle.\n",
        "- La Régression Linéaire est moins sensible à la mise à l'échelle, mais il est intéressant d'observer l'impact."
      ],
      "metadata": {
        "id": "cmXeSubXDCqA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "5.1.2 Régression Linéaire avec Mise à l'Échelle"
      ],
      "metadata": {
        "id": "9idVoZI6A9KC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Train with scaling\n",
        "lr_with_scaling = LinearRegression()\n",
        "lr_with_scaling.fit(X_train, y_train)\n",
        "\n",
        "# Predict on test set\n",
        "y_pred_with_scaling = lr_with_scaling.predict(X_test)"
      ],
      "metadata": {
        "id": "9zva8y-sAxDp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Note** : Dans ce cas, les deux modèles sont entraînés sur des données mises à l'échelle car la régression linéaire n'est pas affectée par la mise à l'échelle en termes de performance, mais la mise à l'échelle peut améliorer la stabilité numérique.\n",
        "\n",
        "5.1.3 Comparaison de la Performance"
      ],
      "metadata": {
        "id": "QSzwfSUkBDK-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate RMSE for both models\n",
        "rmse_no_scaling = np.sqrt(mean_squared_error(y_test, y_pred_no_scaling))\n",
        "rmse_with_scaling = np.sqrt(mean_squared_error(y_test, y_pred_with_scaling))\n",
        "\n",
        "print(f'Linear Regression without Scaling RMSE: {rmse_no_scaling:.4f}')\n",
        "print(f'Linear Regression with Scaling RMSE: {rmse_with_scaling:.4f}')"
      ],
      "metadata": {
        "id": "pxAdWthzBAvE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Discussion :\n",
        "\n",
        "- Observation : Les valeurs de RMSE sont similaires.\n",
        "- Explication : La Régression Linéaire n'est pas sensible à la mise à l'échelle des caractéristiques en termes de prédictions car elle trouve les coefficients optimaux indépendamment des échelles des caractéristiques."
      ],
      "metadata": {
        "id": "8kE2tebRD_Lj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5.2 Modèles Linéaires vs Non-Linéaires <a name=\"linear-vs-non-linear-models\"></a>\n"
      ],
      "metadata": {
        "id": "bnBRmPXJEBYc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "5.2.1 Régression Polynomiale\n",
        "\n"
      ],
      "metadata": {
        "id": "TmmsSbRcBJ9M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Générer des caractéristiques polynomiales\n",
        "poly_features = PolynomialFeatures(degree=2, include_bias=False)\n",
        "X_train_poly = poly_features.fit_transform(X_train)\n",
        "X_test_poly = poly_features.transform(X_test)\n",
        "\n",
        "# Entraîner le modèle\n",
        "poly_model = LinearRegression()\n",
        "poly_model.fit(X_train_poly, y_train)\n",
        "\n",
        "# Prédire sur l'ensemble de test\n",
        "y_pred_poly = poly_model.predict(X_test_poly)"
      ],
      "metadata": {
        "id": "tXETxnmjBHY4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Explication :\n",
        "\n",
        "- La Régression Polynomiale permet de modéliser des relations non linéaires en ajoutant des puissances des caractéristiques originales.\n",
        "- degree=2 signifie que nous incluons les termes au carré et les interactions entre les caractéristiques."
      ],
      "metadata": {
        "id": "6X_Z5Iv3EWKX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "5.2.2 Régression par Arbre de Décision\n",
        "\n",
        "Les arbres de décision peuvent capturer des relations complexes et non linéaires."
      ],
      "metadata": {
        "id": "pimB_JgYBf5M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Entraîner le modèle\n",
        "dt_model = DecisionTreeRegressor(max_depth=5, random_state=42)\n",
        "dt_model.fit(X_train, y_train)\n",
        "\n",
        "# Prédire sur l'ensemble de test\n",
        "y_pred_dt = dt_model.predict(X_test)"
      ],
      "metadata": {
        "id": "1sbXOUoOBiPx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Explication :\n",
        "\n",
        "- Les Arbres de Décision partitionnent l'espace des caractéristiques en régions homogènes.\n",
        "- max_depth=5 limite la profondeur de l'arbre pour éviter le surajustement."
      ],
      "metadata": {
        "id": "0rbvwQKQEpr3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "5.2.3 Comparaison des Modèles"
      ],
      "metadata": {
        "id": "cq4FC9J8Bl93"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Mise à l'échelle des données\n",
        "X_scaled = scaler.fit_transform(data[selected_features])\n",
        "y = data['MedHouseVal']\n",
        "\n",
        "# 2. Division des données\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X_scaled, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# 3. Création et entraînement du modèle\n",
        "lr_model = LinearRegression()\n",
        "lr_model.fit(X_train, y_train)\n",
        "\n",
        "# 4. Prédiction sur les données de test\n",
        "y_pred_dt = lr_model.predict(X_test)\n",
        "\n",
        "# 5. Évaluation du modèle\n",
        "rmse_linear = np.sqrt(mean_squared_error(y_test, y_pred_dt))"
      ],
      "metadata": {
        "id": "DgXaYzHVTyG6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculer le RMSE\n",
        "rmse_linear = np.sqrt(mean_squared_error(y_test, y_pred_with_scaling))\n",
        "rmse_poly = np.sqrt(mean_squared_error(y_test, y_pred_poly))\n",
        "rmse_dt = np.sqrt(mean_squared_error(y_test, y_pred_dt))\n",
        "\n",
        "print(f'RMSE Régression Linéaire : {rmse_linear:.4f}')\n",
        "print(f'RMSE Régression Polynomiale : {rmse_poly:.4f}')\n",
        "print(f'RMSE Arbre de Décision : {rmse_dt:.4f}')"
      ],
      "metadata": {
        "id": "1iOzS-zWBlL_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Observation** :\n",
        "\n",
        "- Comparez les RMSE pour voir quel modèle performe le mieux.\n",
        "- Le modèle avec le RMSE le plus bas est considéré comme ayant la meilleure performance.\n",
        "\n",
        "**Explication** :\n",
        "\n",
        "- Les modèles non linéaires peuvent capturer des relations complexes dans les données.\n",
        "- Cependant, ils peuvent aussi surajuster si la complexité du modèle est trop élevée."
      ],
      "metadata": {
        "id": "rc4QvpweFBNf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6. Métriques d'Évaluation <a name=\"evaluation-metrics\"></a>"
      ],
      "metadata": {
        "id": "myV34gCUFJR6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### 6.1 Comparaison des Modèles en Utilisant les Métriques <a name=\"comparing-models-using-metrics\"></a>"
      ],
      "metadata": {
        "id": "uxdCdBrYBtJL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Il est important de choisir des métriques appropriées pour évaluer la performance des modèles.\n",
        "\n",
        "**Quand Utiliser Chaque Métrique?**\n",
        "\n",
        "- MSE : Lorsque les grandes erreurs sont particulièrement indésirables.\n",
        "- MAE : Pour une mesure plus robuste face aux valeurs aberrantes.\n",
        "- RMSE : Pour interpréter l'erreur dans les mêmes unités que la cible."
      ],
      "metadata": {
        "id": "m2xuvJwYGD81"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_model(y_true, y_pred, model_name):\n",
        "    mse = mean_squared_error(y_true, y_pred)\n",
        "    mae = mean_absolute_error(y_true, y_pred)\n",
        "    rmse = np.sqrt(mse)\n",
        "\n",
        "    print(f'{model_name} Performance:')\n",
        "    print(f'MSE: {mse:.4f}')\n",
        "    print(f'MAE: {mae:.4f}')\n",
        "    print(f'RMSE: {rmse:.4f}')\n",
        "    print('-' * 40)\n",
        "\n",
        "    return {'Model': model_name, 'MSE': mse, 'MAE': mae, 'RMSE': rmse}"
      ],
      "metadata": {
        "id": "tpY85yyCBdBH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "metrics_lr = evaluate_model(y_test, y_pred_with_scaling, 'Linear Regression')\n",
        "metrics_poly = evaluate_model(y_test, y_pred_poly, 'Polynomial Regression')\n",
        "metrics_dt = evaluate_model(y_test, y_pred_dt, 'Decision Tree Regression')"
      ],
      "metadata": {
        "id": "sGQWq-RgCqQn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Compiler les Métriques dans un DataFrame"
      ],
      "metadata": {
        "id": "kE4bSxybC2Dh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a DataFrame\n",
        "metrics_df = pd.DataFrame([metrics_lr, metrics_poly, metrics_dt])\n",
        "metrics_df.set_index('Model', inplace=True)\n",
        "metrics_df"
      ],
      "metadata": {
        "id": "uw9bIrl7C4tT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 7. Effet des Valeurs Aberrantes <a name=\"effect-of-outliers\"></a>\n",
        "Les valeurs aberrantes peuvent affecter significativement la performance du modèle, en particulier avec MSE et RMSE.\n",
        "\n",
        "### 7.1 Introduction de Valeurs Aberrantes"
      ],
      "metadata": {
        "id": "mf9QuhKPB7KV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Introduire des valeurs aberrantes\n",
        "y_train_outliers = y_train.copy()\n",
        "y_train_outliers.iloc[0:5] = y_train_outliers.iloc[0:5] * 1000  # Gonfler les 5 premières valeurs\n",
        "\n",
        "# Réentraîner la Régression Linéaire\n",
        "lr_with_outliers = LinearRegression()\n",
        "lr_with_outliers.fit(X_train, y_train_outliers)\n",
        "\n",
        "# Prédire sur l'ensemble de test\n",
        "y_pred_outliers = lr_with_outliers.predict(X_test)\n",
        "\n",
        "# Évaluer le modèle\n",
        "metrics_outliers = evaluate_model(y_test, y_pred_outliers, 'Régression Linéaire avec Valeurs Aberrantes')"
      ],
      "metadata": {
        "id": "K8b0KtolB4H-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 7.2 Observer l'Impact\n",
        "Comparaison du MSE et du MAE :\n",
        "\n",
        "- Le MSE devrait augmenter significativement en raison du terme au carré qui pénalise les grandes erreurs.\n",
        "- Le MAE peut ne pas augmenter aussi dramatiquement.\n",
        "\n",
        "Discussion :\n",
        "\n",
        "- Pourquoi le MSE augmente-t-il plus que le MAE ?\n",
        "- Quand devrions-nous préférer le MAE au MSE ?\n",
        "\n",
        "Explication :\n",
        "\n",
        "- Le MSE est plus sensible aux valeurs aberrantes en raison du carré des erreurs.\n",
        "- Le MAE fournit une mesure plus robuste en présence de valeurs aberrantes.\n",
        "\n"
      ],
      "metadata": {
        "id": "-qtF4-T0DPG8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 8. Visualisation <a name=\"visualization\"></a>\n"
      ],
      "metadata": {
        "id": "g_X_SauoHbFF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "La visualisation aide à comprendre les performances et les erreurs du modèle.\n",
        "\n"
      ],
      "metadata": {
        "id": "FDWJnbDWH0iR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot Actual vs. Predicted\n",
        "plt.figure(figsize=(8,6))\n",
        "plt.scatter(y_test, y_pred_with_scaling, alpha=0.5)\n",
        "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--')\n",
        "plt.xlabel('Valeur Médiane Réelle des Maisons')\n",
        "plt.ylabel('Valeur Médiane Prédite des Maisons')\n",
        "plt.title('Régression Linéaire : Réel vs Prédit')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Luq9dYBuDJOR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot Actual vs. Predicted\n",
        "plt.figure(figsize=(8,6))\n",
        "plt.scatter(y_test, y_pred_poly, alpha=0.5, color='green')\n",
        "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--')\n",
        "plt.xlabel('Valeur Médiane Réelle des Maisons')\n",
        "plt.ylabel('Valeur Médiane Prédite des Maisons')\n",
        "plt.title('Régression Polynomiale : Réel vs Prédit')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "_0WPpR76Dk_4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Observation** :\n",
        "\n",
        "- Alignement avec la Ligne Rouge : Plus les points sont proches de la ligne, meilleures sont les prédictions.\n"
      ],
      "metadata": {
        "id": "c7lNTcD1D3zw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 9. Retour à la classification"
      ],
      "metadata": {
        "id": "oFgpJlZ9Ic2c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Mapper les étiquettes numériques aux noms des espèces pour faciliter l'interprétation des résultats\n",
        "species_mapping = {0: 'setosa', 1: 'versicolor', 2: 'virginica'}\n",
        "iris_data['Species'] = iris_data['Species'].map(species_mapping)"
      ],
      "metadata": {
        "id": "r2n1NabkIRNf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Entraîner le modèle\n",
        "log_reg = LogisticRegression()\n",
        "log_reg.fit(X_train_iris, y_train_iris)\n",
        "\n",
        "# Prédire sur l'ensemble de test\n",
        "y_pred_log_reg = log_reg.predict(X_test_iris)"
      ],
      "metadata": {
        "id": "Ixsm6_ndIkuB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Entraîner le modèle\n",
        "dt_clf = DecisionTreeClassifier(max_depth=3, random_state=42)\n",
        "dt_clf.fit(X_train_iris, y_train_iris)\n",
        "\n",
        "# Prédire sur l'ensemble de test\n",
        "y_pred_dt = dt_clf.predict(X_test_iris)"
      ],
      "metadata": {
        "id": "bdMhuTEJItNy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_classification_model(y_true, y_pred, model_name):\n",
        "    accuracy = accuracy_score(y_true, y_pred)\n",
        "    precision = precision_score(y_true, y_pred, average='macro')\n",
        "    recall = recall_score(y_true, y_pred, average='macro')\n",
        "    f1 = f1_score(y_true, y_pred, average='macro')\n",
        "\n",
        "    print(f'Performance du {model_name}:')\n",
        "    print(f'Exactitude : {accuracy:.4f}')\n",
        "    print(f'Précision : {precision:.4f}')\n",
        "    print(f'Rappel : {recall:.4f}')\n",
        "    print(f'F1-score : {f1:.4f}')\n",
        "    print('-' * 40)\n",
        "\n",
        "    return {'Modèle': model_name, 'Exactitude': accuracy, 'Précision': precision, 'Rappel': recall, 'F1-score': f1}"
      ],
      "metadata": {
        "id": "mf_GDERoIvZ7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Évaluer les Modèles\n",
        "metrics_log_reg = evaluate_classification_model(y_test_iris, y_pred_log_reg, 'Régression Logistique')\n",
        "metrics_dt = evaluate_classification_model(y_test_iris, y_pred_dt, 'Arbre de Décision')"
      ],
      "metadata": {
        "id": "NyQjhHAhI3VR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Créer un DataFrame\n",
        "metrics_classification_df = pd.DataFrame([metrics_log_reg, metrics_dt])\n",
        "metrics_classification_df.set_index('Modèle', inplace=True)\n",
        "metrics_classification_df"
      ],
      "metadata": {
        "id": "YQ_OpQH9I7On"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "L'ensemble de données Iris est connu pour être relativement simple, avec des frontières bien définies entre les classes. Cela rend les modèles capables d'apprendre parfaitement les relations et d'obtenir une précision de 100 %."
      ],
      "metadata": {
        "id": "d4ysVqURK1HU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Nombre de lignes Train : {X_train_iris.shape[0]}\")\n",
        "print(f\"Nombre de lignes Test  : {X_test_iris.shape[0]}\")"
      ],
      "metadata": {
        "id": "xk9tAyrqJGHh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Afficher la matrice de confusion\n",
        "ConfusionMatrixDisplay.from_estimator(\n",
        "    log_reg, X_test_iris, y_test_iris, display_labels=species_mapping.values())\n",
        "plt.title('Matrice de Confusion - Régression Logistique')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "A8CIaO2ZJDYk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Afficher la matrice de confusion\n",
        "ConfusionMatrixDisplay.from_estimator(\n",
        "    dt_clf, X_test_iris, y_test_iris, display_labels=species_mapping.values())\n",
        "plt.title('Matrice de Confusion - Arbre de Décision')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "oeUI5mK2JMyp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 10. Conclusion <a name=\"conclusion\"></a>"
      ],
      "metadata": {
        "id": "_c6AfGdyMJYi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dans cette session pratique, nous avons :\n",
        "\n",
        "- Exploré les concepts de régression et de classification.\n",
        "- Effectué un prétraitement complet des données.\n",
        "- Entraîné et comparé plusieurs modèles pour la régression et la classification.\n",
        "- Compris et utilisé différentes métriques d'évaluation.\n",
        "- Examiné l'effet des valeurs aberrantes sur la performance des modèles de régression.\n",
        "- Visualisé les résultats pour une meilleure interprétation.\n"
      ],
      "metadata": {
        "id": "9kYN3knWMFEL"
      }
    }
  ]
}